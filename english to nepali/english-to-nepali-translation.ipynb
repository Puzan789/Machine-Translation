{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7512266,"sourceType":"datasetVersion","datasetId":4375468}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"9b44d956-f7b0-4cb3-a77e-b823d2337626","_cell_guid":"65f16341-5748-4a31-820b-7ad93403bc56","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T15:54:02.333248Z","iopub.execute_input":"2024-01-30T15:54:02.334082Z","iopub.status.idle":"2024-01-30T15:54:03.314115Z","shell.execute_reply.started":"2024-01-30T15:54:02.334049Z","shell.execute_reply":"2024-01-30T15:54:03.313191Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nepali-dataset/npi.txt\n/kaggle/input/nepali-dataset/_about.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input,LSTM,Dense\ndata_path='/kaggle/input/nepali-dataset/npi.txt'\nbatch_size=8\nepochs=100\nlatent_dim=512\n","metadata":{"_uuid":"eef9ee9a-17b4-425c-86af-08d56d96f523","_cell_guid":"99615bcf-0205-4e68-9c44-758ade71db26","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T13:28:11.326399Z","iopub.status.idle":"2024-01-30T13:28:11.326741Z","shell.execute_reply.started":"2024-01-30T13:28:11.326574Z","shell.execute_reply":"2024-01-30T13:28:11.326589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith open(data_path,'r',encoding='utf-8') as f:\n    lines=f.read().split('\\n')","metadata":{"_uuid":"a7bfc542-8780-48a7-b59d-f9c490d0869c","_cell_guid":"9ba958b5-33e9-4225-9d63-ef6894a6cf97","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:48:54.347905Z","iopub.execute_input":"2024-01-30T12:48:54.348657Z","iopub.status.idle":"2024-01-30T12:48:54.368588Z","shell.execute_reply.started":"2024-01-30T12:48:54.348624Z","shell.execute_reply":"2024-01-30T12:48:54.367565Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"\ntexts=[]\nfor line in lines:\n    texts.append(line.split('\\t')[0:2])","metadata":{"_uuid":"69219b8f-f5ab-4d82-a4f0-82adab172e4d","_cell_guid":"e864a39a-2827-4aec-94f3-1a2f535c9a05","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:48:56.117112Z","iopub.execute_input":"2024-01-30T12:48:56.117498Z","iopub.status.idle":"2024-01-30T12:48:56.124897Z","shell.execute_reply.started":"2024-01-30T12:48:56.117467Z","shell.execute_reply":"2024-01-30T12:48:56.123833Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"input_texts=[]\noutput_texts=[]\ninput_characters=set()\noutput_characters=set()\nfor i in range(len(texts)-1):\n    input_texts.append(texts[i][0])\n    output_texts.append(texts[i][1])\n    for char in input_texts[i]:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in output_texts[i]:\n            if char not in output_characters:\n                output_characters.add(char)","metadata":{"_uuid":"13242628-693c-4ed0-9161-189ab8772f60","_cell_guid":"6b206446-0d19-44aa-b698-7f4c6fc73dbf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:00.476653Z","iopub.execute_input":"2024-01-30T12:49:00.477347Z","iopub.status.idle":"2024-01-30T12:49:00.504497Z","shell.execute_reply.started":"2024-01-30T12:49:00.477314Z","shell.execute_reply":"2024-01-30T12:49:00.503415Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"print(len(input_texts))\nprint(len(output_texts))\nprint(len(output_characters))\nprint(len(output_characters))","metadata":{"_uuid":"22ec7606-6b28-424f-8842-b0c86171fc1f","_cell_guid":"e0001d88-5993-4d92-8a9a-399bcb61d4b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:02.242543Z","iopub.execute_input":"2024-01-30T12:49:02.243251Z","iopub.status.idle":"2024-01-30T12:49:02.249002Z","shell.execute_reply.started":"2024-01-30T12:49:02.243217Z","shell.execute_reply":"2024-01-30T12:49:02.247959Z"},"trusted":true},"execution_count":201,"outputs":[{"name":"stdout","text":"2405\n2405\n76\n76\n","output_type":"stream"}]},{"cell_type":"code","source":"input_characters=sorted(list(input_characters))\noutput_characters=sorted(list(output_characters))\nnum_encoders_token=len(input_characters)\nnum_decoders_token=len(output_characters)","metadata":{"_uuid":"c7deb697-5263-442a-ada2-70e2d89b9dd7","_cell_guid":"42604c32-5b61-4538-bcf2-614fb40d274a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:04.217205Z","iopub.execute_input":"2024-01-30T12:49:04.217559Z","iopub.status.idle":"2024-01-30T12:49:04.222592Z","shell.execute_reply.started":"2024-01-30T12:49:04.217532Z","shell.execute_reply":"2024-01-30T12:49:04.221455Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"max_encoders_length=max([len(txt) for txt in input_texts])\nmax_decoders_length=max([len(txt) for txt in output_texts])","metadata":{"_uuid":"ec8b696e-ca15-4e37-980d-2d6d74504be4","_cell_guid":"81eee7b1-1bba-4a45-a7aa-ba160a304f55","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:06.437137Z","iopub.execute_input":"2024-01-30T12:49:06.438021Z","iopub.status.idle":"2024-01-30T12:49:06.443023Z","shell.execute_reply.started":"2024-01-30T12:49:06.437961Z","shell.execute_reply":"2024-01-30T12:49:06.442115Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"print(\"num of samples\",len(input_texts))\nprint(\"number of unique input tokens\",num_encoders_token)\nprint(\"number of unique output tokens\",num_decoders_token)\n\nprint(max_encoders_length)\nprint(max_decoders_length)","metadata":{"_uuid":"e157640f-5d7f-44a1-96d7-66e2c0467b6e","_cell_guid":"190997de-daf9-48b5-b652-60a0f0522602","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:08.376606Z","iopub.execute_input":"2024-01-30T12:49:08.377600Z","iopub.status.idle":"2024-01-30T12:49:08.382781Z","shell.execute_reply.started":"2024-01-30T12:49:08.377563Z","shell.execute_reply":"2024-01-30T12:49:08.381739Z"},"trusted":true},"execution_count":204,"outputs":[{"name":"stdout","text":"num of samples 2405\nnumber of unique input tokens 67\nnumber of unique output tokens 76\n122\n102\n","output_type":"stream"}]},{"cell_type":"code","source":"input_token_index=dict(\n    [(char,i) for i,char in enumerate(input_characters)]\n)\noutput_token_index=dict(\n    [(char,i) for i,char in enumerate(output_characters)]\n)","metadata":{"_uuid":"f713616a-6359-418c-9a6d-17e7395e1db6","_cell_guid":"2e5e41a6-bfc4-41c9-80a9-663482c61f30","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:12.904927Z","iopub.execute_input":"2024-01-30T12:49:12.905858Z","iopub.status.idle":"2024-01-30T12:49:12.910834Z","shell.execute_reply.started":"2024-01-30T12:49:12.905827Z","shell.execute_reply":"2024-01-30T12:49:12.909683Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"encoder_input_data=np.zeros(\n    (len(input_texts),max_encoders_length,num_encoders_token),dtype='float32')\n\ndecoder_input_data=np.zeros(\n    (len(output_texts),max_decoders_length,num_decoders_token),dtype='float32')\n\ndecoder_target_data=np.zeros(\n    (len(output_texts),max_decoders_length,num_decoders_token)\n,dtype='float32')","metadata":{"_uuid":"c1ccb7a7-a234-4c9c-961c-a39d3b96b344","_cell_guid":"57f77a71-816e-403c-809f-50be21532135","collapsed":false,"scrolled":true,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:16.589195Z","iopub.execute_input":"2024-01-30T12:49:16.590065Z","iopub.status.idle":"2024-01-30T12:49:16.595653Z","shell.execute_reply.started":"2024-01-30T12:49:16.590035Z","shell.execute_reply":"2024-01-30T12:49:16.594576Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"for i, (input_text, output_text) in enumerate(zip(input_texts, output_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1\n    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1\n    for t, char in enumerate(output_text):\n        decoder_input_data[i, t, output_token_index[char]] = 1\n        if t > 0:     \n            decoder_target_data[i, t - 1, output_token_index[char]] = 1\ndecoder_input_data[i, t + 1:, output_token_index[' ']] = 1\ndecoder_target_data[i, t:, output_token_index[' ']] = 1\n","metadata":{"_uuid":"f9c9dcfb-7e6c-4cba-a128-26171b04bb77","_cell_guid":"4564d292-54a9-43c0-a6d4-d343ff2cf6a6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-30T12:49:19.450576Z","iopub.execute_input":"2024-01-30T12:49:19.450933Z","iopub.status.idle":"2024-01-30T12:49:19.662625Z","shell.execute_reply.started":"2024-01-30T12:49:19.450906Z","shell.execute_reply":"2024-01-30T12:49:19.661803Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"print(decoder_input_data[0].shape)\nprint(encoder_input_data[0].shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T12:49:21.327073Z","iopub.execute_input":"2024-01-30T12:49:21.328079Z","iopub.status.idle":"2024-01-30T12:49:21.333349Z","shell.execute_reply.started":"2024-01-30T12:49:21.328037Z","shell.execute_reply":"2024-01-30T12:49:21.332247Z"},"trusted":true},"execution_count":208,"outputs":[{"name":"stdout","text":"(102, 76)\n(122, 67)\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder_inputs=Input(shape=(None,num_encoders_token))\nencoder=LSTM(latent_dim,return_state=True)\n\nencoder_outputs,state_h,state_c=encoder(encoder_inputs)\nencoder_states=[state_h,state_c]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T13:29:03.345813Z","iopub.execute_input":"2024-01-30T13:29:03.346520Z","iopub.status.idle":"2024-01-30T13:29:03.598129Z","shell.execute_reply.started":"2024-01-30T13:29:03.346484Z","shell.execute_reply":"2024-01-30T13:29:03.597279Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"decoder_inputs=Input(shape=(None,num_decoders_token))\ndecoder_lstm=LSTM(latent_dim,return_state=True,return_sequences=True)\n\ndecoder_outputs,_,_=decoder_lstm(decoder_inputs,initial_state=encoder_states)\ndecoder_dense=Dense(num_decoders_token,activation='softmax')\ndecoder_outputs=decoder_dense(decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T13:29:05.402927Z","iopub.execute_input":"2024-01-30T13:29:05.403782Z","iopub.status.idle":"2024-01-30T13:29:05.687303Z","shell.execute_reply.started":"2024-01-30T13:29:05.403747Z","shell.execute_reply":"2024-01-30T13:29:05.686319Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"from keras.layers import LSTM, Input, Dense,GRU,Dropout,LayerNormalization\n\n# Encoder\nencoder_inputs = Input(shape=(None, num_encoders_token))\nencoder_lstm_1 = GRU(latent_dim, return_sequences=True, return_state=True)\nencoder_outputs_1, state_h_1 = encoder_lstm_1(encoder_inputs)\nencoder_outputs_1 = Dropout(0.2)(encoder_outputs_1)\nencoder_outputs_1 = LayerNormalization()(encoder_outputs_1)\n\n\nencoder_lstm_2 = GRU(latent_dim,return_sequences=True,  return_state=True)\nencoder_outputs_2, state_h_2 = encoder_lstm_2(encoder_outputs_1)\nencoder_outputs_2 = Dropout(0.2)(encoder_outputs_2)\nencoder_outputs_2 = LayerNormalization()(encoder_outputs_2)\n\n\n\nencoder_lstm_3= GRU(latent_dim, return_state=True)\nencoder_outputs, state_h = encoder_lstm_3(encoder_outputs_2)\nencoder_outputs = Dropout(0.2)(encoder_outputs)\nencoder_outputs = LayerNormalization()(encoder_outputs)\n\nencoder_states = state_h\n\n# Decoder\ndecoder_inputs = Input(shape=(None, num_decoders_token))\ndecoder_lstm_1 = GRU(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs_1, _ = decoder_lstm_1(decoder_inputs, initial_state=encoder_states)\ndecoder_outputs_1 = Dropout(0.2)(decoder_outputs_1)\ndecoder_outputs_1= LayerNormalization()(decoder_outputs_1)\n\n\ndecoder_lstm_2 = GRU(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs_2, _ = decoder_lstm_2(decoder_outputs_1)\ndecoder_outputs_2 = Dropout(0.2)(decoder_outputs_2)\ndecoder_outputs_2= LayerNormalization()(decoder_outputs_2)\n\n\ndecoder_lstm_2 = GRU(latent_dim,return_state=True)\ndecoder_outputs, _ = decoder_lstm_2(decoder_outputs_2)\ndecoder_outputs = Dropout(0.2)(decoder_outputs)\ndecoder_outputs= LayerNormalization()(decoder_outputs)\n\n\n\ndecoder_dense = Dense(num_decoders_token, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T13:55:01.595118Z","iopub.execute_input":"2024-01-30T13:55:01.595787Z","iopub.status.idle":"2024-01-30T13:55:03.105828Z","shell.execute_reply.started":"2024-01-30T13:55:01.595753Z","shell.execute_reply":"2024-01-30T13:55:03.105020Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\noptimizer=Adam(learning_rate=0.0001)\nmodel.summary()\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit([encoder_input_data,decoder_input_data],\n                  decoder_target_data,\n                  epochs=epochs,\n                  verbose=1,\n                  validation_split=0.2\n                 )","metadata":{"execution":{"iopub.status.busy":"2024-01-30T13:55:07.535220Z","iopub.execute_input":"2024-01-30T13:55:07.535611Z","iopub.status.idle":"2024-01-30T13:57:08.542287Z","shell.execute_reply.started":"2024-01-30T13:55:07.535572Z","shell.execute_reply":"2024-01-30T13:57:08.541340Z"},"trusted":true},"execution_count":259,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, None, 67)]           0         []                            \n                                                                                                  \n input_4 (InputLayer)        [(None, None, 76)]           0         []                            \n                                                                                                  \n lstm (LSTM)                 [(None, 200),                214400    ['input_2[0][0]']             \n                              (None, 200),                                                        \n                              (None, 200)]                                                        \n                                                                                                  \n lstm_2 (LSTM)               [(None, None, 200),          221600    ['input_4[0][0]',             \n                              (None, 200),                           'lstm[0][1]',                \n                              (None, 200)]                           'lstm[0][2]']                \n                                                                                                  \n dense_1 (Dense)             (None, None, 76)             15276     ['lstm_2[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 451276 (1.72 MB)\nTrainable params: 451276 (1.72 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\nEpoch 1/100\n61/61 [==============================] - 6s 31ms/step - loss: 0.5401 - accuracy: 0.8661 - val_loss: 1.1936 - val_accuracy: 0.7119\nEpoch 2/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5393 - accuracy: 0.8662 - val_loss: 1.1928 - val_accuracy: 0.7123\nEpoch 3/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5388 - accuracy: 0.8663 - val_loss: 1.1935 - val_accuracy: 0.7116\nEpoch 4/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5386 - accuracy: 0.8663 - val_loss: 1.1959 - val_accuracy: 0.7117\nEpoch 5/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5389 - accuracy: 0.8664 - val_loss: 1.1928 - val_accuracy: 0.7119\nEpoch 6/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5381 - accuracy: 0.8664 - val_loss: 1.1972 - val_accuracy: 0.7115\nEpoch 7/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5378 - accuracy: 0.8666 - val_loss: 1.1929 - val_accuracy: 0.7122\nEpoch 8/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5369 - accuracy: 0.8669 - val_loss: 1.1927 - val_accuracy: 0.7122\nEpoch 9/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5366 - accuracy: 0.8670 - val_loss: 1.1926 - val_accuracy: 0.7116\nEpoch 10/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5366 - accuracy: 0.8671 - val_loss: 1.1925 - val_accuracy: 0.7118\nEpoch 11/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5364 - accuracy: 0.8671 - val_loss: 1.1913 - val_accuracy: 0.7119\nEpoch 12/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5362 - accuracy: 0.8671 - val_loss: 1.1897 - val_accuracy: 0.7123\nEpoch 13/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5368 - accuracy: 0.8669 - val_loss: 1.1900 - val_accuracy: 0.7127\nEpoch 14/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5375 - accuracy: 0.8667 - val_loss: 1.1955 - val_accuracy: 0.7118\nEpoch 15/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5375 - accuracy: 0.8667 - val_loss: 1.1934 - val_accuracy: 0.7121\nEpoch 16/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5365 - accuracy: 0.8672 - val_loss: 1.1928 - val_accuracy: 0.7120\nEpoch 17/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5360 - accuracy: 0.8672 - val_loss: 1.1913 - val_accuracy: 0.7120\nEpoch 18/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5353 - accuracy: 0.8674 - val_loss: 1.1899 - val_accuracy: 0.7123\nEpoch 19/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5350 - accuracy: 0.8675 - val_loss: 1.1904 - val_accuracy: 0.7122\nEpoch 20/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5386 - accuracy: 0.8664 - val_loss: 1.2116 - val_accuracy: 0.7085\nEpoch 21/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5395 - accuracy: 0.8662 - val_loss: 1.1972 - val_accuracy: 0.7115\nEpoch 22/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5368 - accuracy: 0.8669 - val_loss: 1.1921 - val_accuracy: 0.7121\nEpoch 23/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5420 - accuracy: 0.8657 - val_loss: 1.2127 - val_accuracy: 0.7085\nEpoch 24/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5442 - accuracy: 0.8654 - val_loss: 1.1958 - val_accuracy: 0.7111\nEpoch 25/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5443 - accuracy: 0.8652 - val_loss: 1.1996 - val_accuracy: 0.7106\nEpoch 26/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5398 - accuracy: 0.8663 - val_loss: 1.1978 - val_accuracy: 0.7115\nEpoch 27/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5378 - accuracy: 0.8667 - val_loss: 1.1943 - val_accuracy: 0.7117\nEpoch 28/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5367 - accuracy: 0.8671 - val_loss: 1.1937 - val_accuracy: 0.7117\nEpoch 29/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5361 - accuracy: 0.8672 - val_loss: 1.1925 - val_accuracy: 0.7122\nEpoch 30/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5356 - accuracy: 0.8673 - val_loss: 1.1937 - val_accuracy: 0.7120\nEpoch 31/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5354 - accuracy: 0.8675 - val_loss: 1.1918 - val_accuracy: 0.7125\nEpoch 32/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5350 - accuracy: 0.8675 - val_loss: 1.1919 - val_accuracy: 0.7123\nEpoch 33/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5347 - accuracy: 0.8676 - val_loss: 1.1919 - val_accuracy: 0.7123\nEpoch 34/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5346 - accuracy: 0.8676 - val_loss: 1.1913 - val_accuracy: 0.7122\nEpoch 35/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5344 - accuracy: 0.8676 - val_loss: 1.1918 - val_accuracy: 0.7122\nEpoch 36/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5342 - accuracy: 0.8677 - val_loss: 1.1914 - val_accuracy: 0.7124\nEpoch 37/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5347 - accuracy: 0.8675 - val_loss: 1.1934 - val_accuracy: 0.7115\nEpoch 38/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5346 - accuracy: 0.8677 - val_loss: 1.1918 - val_accuracy: 0.7120\nEpoch 39/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5339 - accuracy: 0.8677 - val_loss: 1.1926 - val_accuracy: 0.7118\nEpoch 40/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5337 - accuracy: 0.8677 - val_loss: 1.1924 - val_accuracy: 0.7119\nEpoch 41/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5336 - accuracy: 0.8677 - val_loss: 1.1919 - val_accuracy: 0.7121\nEpoch 42/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5334 - accuracy: 0.8678 - val_loss: 1.1917 - val_accuracy: 0.7120\nEpoch 43/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5333 - accuracy: 0.8679 - val_loss: 1.1911 - val_accuracy: 0.7123\nEpoch 44/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5329 - accuracy: 0.8680 - val_loss: 1.1915 - val_accuracy: 0.7122\nEpoch 45/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5329 - accuracy: 0.8680 - val_loss: 1.1901 - val_accuracy: 0.7123\nEpoch 46/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5328 - accuracy: 0.8681 - val_loss: 1.1909 - val_accuracy: 0.7124\nEpoch 47/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5326 - accuracy: 0.8681 - val_loss: 1.1911 - val_accuracy: 0.7124\nEpoch 48/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5325 - accuracy: 0.8682 - val_loss: 1.1917 - val_accuracy: 0.7122\nEpoch 49/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5324 - accuracy: 0.8681 - val_loss: 1.1911 - val_accuracy: 0.7123\nEpoch 50/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5323 - accuracy: 0.8683 - val_loss: 1.1912 - val_accuracy: 0.7121\nEpoch 51/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5321 - accuracy: 0.8683 - val_loss: 1.1922 - val_accuracy: 0.7119\nEpoch 52/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5322 - accuracy: 0.8682 - val_loss: 1.1899 - val_accuracy: 0.7123\nEpoch 53/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5318 - accuracy: 0.8683 - val_loss: 1.1910 - val_accuracy: 0.7123\nEpoch 54/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5318 - accuracy: 0.8684 - val_loss: 1.1908 - val_accuracy: 0.7122\nEpoch 55/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5317 - accuracy: 0.8684 - val_loss: 1.1913 - val_accuracy: 0.7121\nEpoch 56/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5315 - accuracy: 0.8684 - val_loss: 1.1913 - val_accuracy: 0.7123\nEpoch 57/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5315 - accuracy: 0.8685 - val_loss: 1.1925 - val_accuracy: 0.7120\nEpoch 58/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5313 - accuracy: 0.8685 - val_loss: 1.1913 - val_accuracy: 0.7122\nEpoch 59/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5311 - accuracy: 0.8685 - val_loss: 1.1901 - val_accuracy: 0.7126\nEpoch 60/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5311 - accuracy: 0.8685 - val_loss: 1.1916 - val_accuracy: 0.7123\nEpoch 61/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5311 - accuracy: 0.8685 - val_loss: 1.1915 - val_accuracy: 0.7124\nEpoch 62/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5308 - accuracy: 0.8686 - val_loss: 1.1922 - val_accuracy: 0.7119\nEpoch 63/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5307 - accuracy: 0.8686 - val_loss: 1.1915 - val_accuracy: 0.7122\nEpoch 64/100\n61/61 [==============================] - 1s 21ms/step - loss: 0.5306 - accuracy: 0.8686 - val_loss: 1.1913 - val_accuracy: 0.7125\nEpoch 65/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5308 - accuracy: 0.8687 - val_loss: 1.1906 - val_accuracy: 0.7125\nEpoch 66/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5305 - accuracy: 0.8685 - val_loss: 1.1899 - val_accuracy: 0.7126\nEpoch 67/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5302 - accuracy: 0.8689 - val_loss: 1.1910 - val_accuracy: 0.7126\nEpoch 68/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5302 - accuracy: 0.8688 - val_loss: 1.1878 - val_accuracy: 0.7130\nEpoch 69/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5301 - accuracy: 0.8688 - val_loss: 1.1923 - val_accuracy: 0.7120\nEpoch 70/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5354 - accuracy: 0.8677 - val_loss: 1.2395 - val_accuracy: 0.7037\nEpoch 71/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5583 - accuracy: 0.8616 - val_loss: 1.2164 - val_accuracy: 0.7072\nEpoch 72/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5494 - accuracy: 0.8636 - val_loss: 1.2207 - val_accuracy: 0.7066\nEpoch 73/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5512 - accuracy: 0.8632 - val_loss: 1.2147 - val_accuracy: 0.7079\nEpoch 74/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5491 - accuracy: 0.8635 - val_loss: 1.1994 - val_accuracy: 0.7108\nEpoch 75/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5408 - accuracy: 0.8658 - val_loss: 1.2047 - val_accuracy: 0.7093\nEpoch 76/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5437 - accuracy: 0.8647 - val_loss: 1.2043 - val_accuracy: 0.7100\nEpoch 77/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5398 - accuracy: 0.8660 - val_loss: 1.1946 - val_accuracy: 0.7117\nEpoch 78/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5366 - accuracy: 0.8667 - val_loss: 1.1919 - val_accuracy: 0.7125\nEpoch 79/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5357 - accuracy: 0.8671 - val_loss: 1.1908 - val_accuracy: 0.7127\nEpoch 80/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5343 - accuracy: 0.8675 - val_loss: 1.1904 - val_accuracy: 0.7130\nEpoch 81/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5338 - accuracy: 0.8677 - val_loss: 1.1907 - val_accuracy: 0.7132\nEpoch 82/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5334 - accuracy: 0.8678 - val_loss: 1.1906 - val_accuracy: 0.7131\nEpoch 83/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5328 - accuracy: 0.8678 - val_loss: 1.1898 - val_accuracy: 0.7133\nEpoch 84/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5324 - accuracy: 0.8680 - val_loss: 1.1894 - val_accuracy: 0.7135\nEpoch 85/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5321 - accuracy: 0.8682 - val_loss: 1.1898 - val_accuracy: 0.7131\nEpoch 86/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5317 - accuracy: 0.8684 - val_loss: 1.1898 - val_accuracy: 0.7132\nEpoch 87/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5314 - accuracy: 0.8683 - val_loss: 1.1891 - val_accuracy: 0.7134\nEpoch 88/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5312 - accuracy: 0.8684 - val_loss: 1.1890 - val_accuracy: 0.7135\nEpoch 89/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5308 - accuracy: 0.8685 - val_loss: 1.1895 - val_accuracy: 0.7133\nEpoch 90/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5307 - accuracy: 0.8685 - val_loss: 1.1897 - val_accuracy: 0.7134\nEpoch 91/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5305 - accuracy: 0.8686 - val_loss: 1.1892 - val_accuracy: 0.7132\nEpoch 92/100\n61/61 [==============================] - 1s 18ms/step - loss: 0.5303 - accuracy: 0.8686 - val_loss: 1.1888 - val_accuracy: 0.7133\nEpoch 93/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5302 - accuracy: 0.8686 - val_loss: 1.1905 - val_accuracy: 0.7130\nEpoch 94/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5301 - accuracy: 0.8687 - val_loss: 1.1898 - val_accuracy: 0.7131\nEpoch 95/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5300 - accuracy: 0.8687 - val_loss: 1.1907 - val_accuracy: 0.7129\nEpoch 96/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5299 - accuracy: 0.8687 - val_loss: 1.1902 - val_accuracy: 0.7131\nEpoch 97/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5298 - accuracy: 0.8688 - val_loss: 1.1900 - val_accuracy: 0.7130\nEpoch 98/100\n61/61 [==============================] - 1s 23ms/step - loss: 0.5295 - accuracy: 0.8688 - val_loss: 1.1903 - val_accuracy: 0.7129\nEpoch 99/100\n61/61 [==============================] - 1s 20ms/step - loss: 0.5294 - accuracy: 0.8689 - val_loss: 1.1889 - val_accuracy: 0.7131\nEpoch 100/100\n61/61 [==============================] - 1s 19ms/step - loss: 0.5292 - accuracy: 0.8690 - val_loss: 1.1892 - val_accuracy: 0.7130\n","output_type":"stream"},{"execution_count":259,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x791278799ba0>"},"metadata":{}}]},{"cell_type":"code","source":"model.save(\"predmodel.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-01-30T13:12:52.876071Z","iopub.execute_input":"2024-01-30T13:12:52.876457Z","iopub.status.idle":"2024-01-30T13:12:52.917416Z","shell.execute_reply.started":"2024-01-30T13:12:52.876426Z","shell.execute_reply":"2024-01-30T13:12:52.916492Z"},"trusted":true},"execution_count":218,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder_model = Model(encoder_inputs, encoder_states)\n\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_outputs, state_h, state_c = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs] + decoder_states)\ndef decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n\n    # Sampling loop for a batch of sequences (assuming batch size 1).\n    stop_condition = False\n    decoded_sentence = ''\n\n    while not stop_condition:\n        # Predict the next token\n        output_tokens, states_value = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        # Exit condition: either hit max length or find stop character.\n        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.0\n\n    return decoded_sentence\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T14:11:53.908204Z","iopub.execute_input":"2024-01-30T14:11:53.908567Z","iopub.status.idle":"2024-01-30T14:11:54.166491Z","shell.execute_reply.started":"2024-01-30T14:11:53.908537Z","shell.execute_reply":"2024-01-30T14:11:54.165712Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"for seq_index in range(10):\n    input_seq=encoder_input_data[seq_index:seq_index+1]\n    decoded_sentence=decode_sequence(input_seq)\n    print('--')\n    print('Input Sentence ',input_texts[seq_index])\n    print('Decoded Sentence ', decoded_sentence)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-30T14:11:56.706530Z","iopub.execute_input":"2024-01-30T14:11:56.707049Z","iopub.status.idle":"2024-01-30T14:11:57.703699Z","shell.execute_reply.started":"2024-01-30T14:11:56.707006Z","shell.execute_reply":"2024-01-30T14:11:57.702395Z"},"trusted":true},"execution_count":288,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 885ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[288], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     input_seq\u001b[38;5;241m=\u001b[39mencoder_input_data[seq_index:seq_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     decoded_sentence\u001b[38;5;241m=\u001b[39m\u001b[43mdecode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput Sentence \u001b[39m\u001b[38;5;124m'\u001b[39m,input_texts[seq_index])\n","Cell \u001b[0;32mIn[287], line 28\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     24\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Predict the next token\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     output_tokens, h, c \u001b[38;5;241m=\u001b[39m decoder_model\u001b[38;5;241m.\u001b[39mpredict([target_seq] \u001b[38;5;241m+\u001b[39m [states_value[\u001b[38;5;241m0\u001b[39m], \u001b[43mstates_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m])\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Sample a token\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n","\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"],"ename":"IndexError","evalue":"index 1 is out of bounds for axis 0 with size 1","output_type":"error"}]},{"cell_type":"code","source":"print(tokenizer.word_index)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T14:04:29.031943Z","iopub.execute_input":"2024-01-30T14:04:29.032340Z","iopub.status.idle":"2024-01-30T14:04:29.038014Z","shell.execute_reply.started":"2024-01-30T14:04:29.032307Z","shell.execute_reply":"2024-01-30T14:04:29.036888Z"},"trusted":true},"execution_count":270,"outputs":[{"name":"stdout","text":"{' ': 1, 'e': 2, 't': 3, 'o': 4, 'ा': 5, 'a': 6, '्': 7, 'i': 8, 'न': 9, 'म': 10, 'n': 11, 's': 12, 'र': 13, 'क': 14, 'h': 15, 'r': 16, 'ो': 17, 'े': 18, 'ल': 19, 'ि': 20, 'm': 21, 'd': 22, 'ह': 23, '.': 24, '।': 25, 'l': 26, 'स': 27, 'ु': 28, 'y': 29, 'छ': 30, 'w': 31, 'u': 32, 'त': 33, 'य': 34, 'ट': 35, 'प': 36, 'ी': 37, 'ग': 38, 'g': 39, 'c': 40, 'ै': 41, 'ई': 42, '?': 43, \"'\": 44, 'द': 45, 'ब': 46, 'f': 47, 'b': 48, 'k': 49, 'p': 50, 'ँ': 51, 'v': 52, 'भ': 53, 'ज': 54, 'च': 55, 'ए': 56, 'उ': 57, 'थ': 58, 'व': 59, 'ख': 60, 'ं': 61, 'अ': 62, 'ध': 63, 'फ': 64, 'ू': 65, 'आ': 66, ',': 67, 'श': 68, 'ड': 69, 'ौ': 70, 'इ': 71, 'ष': 72, 'ठ': 73, 'x': 74, 'ण': 75, 'झ': 76, '\"': 77, 'ढ': 78, 'घ': 79, 'ृ': 80, 'j': 81, 'z': 82, 'ऊ': 83, 'q': 84, '!': 85, 'ङ': 86, '0': 87, '-': 88, 'औ': 89, '१': 90, '3': 91, 'ओ': 92, '३': 93, '०': 94, 'ः': 95, '1': 96, 'ञ': 97, ':': 98, '2': 99, '\\u200b': 100, 'ऋ': 101, '9': 102, '९': 103, '4': 104, '२': 105, '४': 106, '€': 107, '\\u200d': 108}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}